---
title: "Useful theorems and the sketch of proof"
author: "Saki Kuzushima"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{amsfonts}
   - \usepackage{amsmath}
   - \usepackage{graphicx}
output: 
  pdf_document:
    toc: true
---

\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}


## Sum of exponential random variables is a gamma random variable

Theorem:
If $X_i \stackrel{i.i.d}\sim Expo(\lambda)$, $i = 1...n$, then $Y = \sum_{i=1}^n X_i \sim Gamma(n, \lambda)$.

Proof:

First, recall that if $X\sim Expo(\lambda)$, 
$$
M_X(t) = \frac{\lambda}{\lambda - t}, \quad (t < \lambda)
$$

if $Z \sim Gamma(\alpha, \beta)$, 
$$
M_Z(t) = (\frac{1}{1 - \beta t})^{-\alpha}
$$
Observe that
$$
\begin{aligned}
M_Y(t) &= \E[e^{tY}] \\
&= \E[e^{t\sum_{i=1}^n X_i}] \\
&= \E[\prod_{i=1}^n e^{tX_i}] \\
&= \prod_{i=1}^n \E[e^{tX_i}] \\
&=  \prod_{i=1}^n \frac{\lambda}{\lambda - t} \\
&= (\frac{\lambda}{\lambda - t})^n \\
&=  (\frac{\lambda - t}{\lambda})^{-n} \\
&= (1 - \frac{t}{\lambda})^{-n}
\end{aligned}
$$

This is an mgf of Gamma distribution. So, $Y \sim Gamma(n, \lambda)$. 


## Linear combination of Gaussian random variables is also Gaussian

Theorem:
if $X \sim N(\mu, \sigma^2)$, and $Y = aX + b$, ($a \neq 0$), then $Y \sim N(a\mu + b, a^2\sigma^2)$. 

Proof:
Recall that if $X \sim N(\mu, \sigma^2)$
$$
M_X(t) = e^{\mu t + \frac{\sigma^2}{2}t^2}
$$

Then, 
$$
\begin{aligned}
M_Y(t) &= \E[e^{t(aX + b)}] \\
&=\E[e^{taX + tb}] \\
&=e^{tb} \E[e^{taX}] \\
&= e^{tb} M_X(ta) \\
&= e^{tb} e^{\mu t + \frac{\sigma^2}{2}t^2} \\
&= exp(tb + t\mu a + \frac{\sigma^2}{2}t^2) \\
&= exp((a\mu + b)t + \frac{a^2\sigma^2}{2}t^2)
\end{aligned}
$$

This is also an mgf of Gaussian. $Y \sim N(a\mu + b, a^2 \sigma^2)$.  


## Distribution of maximum values

Theorem:
If $X_1...X_n \stackrel{i.i.d}\sim f_X(x)$, and $Y \equiv max\{X_1...X_n\}$, then $f_Y(y) = n F_X^{n-1}(y) f_X(y)$.

Proof:

$$
\begin{aligned}
F_Y(y) &= P(Y \leq y) \\
&= P(max\{X_1...X_n\} \leq y) \\
&= P(X_1 \leq y) ...P(X_n \leq y) \\
&= F_X(y)...F_X(y) \\
&= F_X^n(y)
\end{aligned}
$$
Then, because $f_Y(y) = \frac{\partial}{\partial y} F_Y(y)$,
$$
\begin{aligned}
  f_Y(y) = n F_X^{n-1}(y)f_X(y)
\end{aligned}
$$


## The Dirichlet distribution belongs to the exponential family

The fact that the Dirichlet distribution belongs to the exponential family is useful. While the expression of the Dirichlet in terms of the exponential family is widely available, the derivation is not. The following sketches the conversion from the usual expression of the pdf of Dirichlet distribution to the form in terms of the exponential family.  

The pdf of the Dirichlet distribution is 
\begin{align}
  p(\theta|\alpha) = \frac{1}{B(\alpha)}\prod_{i=1}^K \theta_i^{\alpha_i - 1}
\end{align}
where $\theta = [\theta_1....\theta_K]^\intercal$, and $\sum_{i=1}^K \theta_i = 1$, $\theta_i \geq 0, \forall i \in \{1,2,...,K\}$.

The exponential family has the following general pdf
\begin{align}
  p(\theta|\eta) = h(\theta) \exp(\eta^\intercal t(\theta) - A(\eta))
\end{align}

where $t(\theta)$ is the sufficient statistic, $\eta$ is called the natural parameter, $A(\eta)$ is the log normalization factor, and $h(x)$ is the base measure.

It is known that the Dirichlet distribution belongs to the exponential family, and the parameters are

- The natural parameter: $\eta = \alpha = [\alpha_1...\alpha_K]^\intercal$
- The sufficient statistic: $t(\theta) = \log \theta = \log[\theta_1, ...\theta_K]^\intercal$.
- The log normalization factor: $A(\eta) = \sum_{i=1}^K \log \Gamma(\eta_i) - \log \Gamma(\sum_{i=1}^K \eta_i)$
- The base measure: $h(x) = \frac{1}{\prod_{i=1}^K} \theta_i$

The following sketches why the parameters are expressed in these ways. 

First, recall that $B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$). Then the pdf of the Dirichlet distribution is 
$$
\begin{aligned}
p(\theta|\alpha) &= \frac{1}{B(\alpha)} \prod_{i=1}^K \theta_i^{\alpha_i - 1} \\
&= \frac{\Gamma(\sum_{i=1}^K \alpha_i)}{\prod_{i=1}^K\Gamma(\alpha_i)}\cdot \frac{\prod_{i=1}^K \theta_i^{\alpha_i}}{\prod_{i=1}^K \theta_i}
\end{aligned}
$$
Taking the exponential and log, 
$$
\begin{aligned}
p(\theta|\alpha) 
&= \frac{\Gamma(\sum_{i=1}^K \alpha_i)}{\prod_{i=1}^K\Gamma(\alpha_i)}\cdot \frac{\prod_{i=1}^K \theta_i^{\alpha_i}}{\prod_{i=1}^K \theta_i} \\
&= \frac{1}{\prod_{i=1}^K \theta_i} \exp\Big[\log \frac{\Gamma(\sum_{i=1}^K \alpha_i)}{\prod_{i=1}^K\Gamma(\alpha_i)}\prod_{i=1}^K \theta_i^{\alpha_i}\Big] \\
&= \frac{1}{\prod_{i=1}^K \theta_i} \exp\Big[\log \Gamma(\sum_{i=1}^K \alpha_i) - \log\prod_{i=1}^K\Gamma(\alpha_i) + \log\prod_{i=1}^K \theta_i^{\alpha_i}\Big] \\
&=  \frac{1}{\prod_{i=1}^K \theta_i} \exp\Big[\log \Gamma(\sum_{i=1}^K \alpha_i) - \sum_{i=1}^K \log \Gamma(\alpha_i) + \sum_{i=1}^K \alpha_i \log \theta_i\Big] \\
&= \frac{1}{\prod_{i=1}^K \theta_i} \exp\Big[\alpha^\intercal \log \theta 
- \big\{\sum_{i=1}^K\log \Gamma(\alpha_i) -
\log \Gamma(\sum_{i=1}^K \alpha_i) \big\} \Big] \\
\end{aligned}
$$

Comparison of this expression with the general pdf of the exponential family yields the parameters listed above. 










## The expectation of the sufficient statistic of the exponential family is the derivative of the log normalizing factor 

Note that this is useful in the derivation of the original variational inference for LDA (in Blei et al 2003). 

Theorem:

\begin{align}
  \E_\theta[t(\theta)] = \frac{\partial}{\partial \eta} A(\eta) 
\end{align}

Proof:

Using the fact that the pdf must integrate to one, we first express $a(\eta)$ by the other parameters. 

$$
\begin{aligned}
  &1 = \int_\theta p(\theta|\eta) d\theta = \int_\theta h(\theta) \exp(\eta\ t(\theta) - A(\eta)) d\theta \\
  &\iff 1 = \frac{1}{\exp A(\eta)} \int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta \\
  &\iff \exp A(\eta) = \int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta \\
  &\iff A(\eta) = \log \int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta \\
\end{aligned}
$$
Let $g(\eta) = \frac{1}{\exp A(\eta)}$. Then this is also equivalent to 
\begin{align}
1 = g(\eta) \int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta 
\end{align}

Taking the derivative of Eq (3) with respect to $\eta$, 
$$
\begin{aligned}
0 &= \frac{\partial}{\partial \eta}\Big[ g(\eta)\int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta \Big]\\
&=   g'(\eta)\int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta +
g(\eta) \frac{\partial}{\partial \eta}\int_\theta h(\theta) \exp(\eta\ t(\theta)) d\theta \\
&= \frac{g'(\eta)}{g(\eta)} + g(\eta) \int_\theta h(\theta) \exp(\eta\ t(\theta)) t(\theta) d\theta \\
&= \frac{g'(\eta)}{g(\eta)} + \int_\theta g(\eta) h(\theta) \exp(\eta\ t(\theta)) t(\theta) d\theta \\
&= \frac{g'(\eta)}{g(\eta)} + \E_\theta[t(\theta)]  \\
\end{aligned}
$$

i.e. 
\begin{align}
  \E_\theta[t(\theta)] = -\frac{g'(\eta)}{g(\eta)} = -\frac{\partial}{\partial \eta}log(g(\eta))
\end{align}
because $\frac{\partial}{\partial \eta}log(g(\eta)) = \frac{1}{g(\eta)}\cdot\frac{\partial}{\partial \eta}g(\eta)$.

Because $g(\eta) = \frac{1}{\exp(A\eta))} = -\exp(A(\eta))$, Eq (4) is equivalent to
\begin{align}
  \E[t(\theta)] = -\frac{\partial}{\partial \eta}log(g(\eta)) =\frac{\partial}{\partial \eta} A(\eta)
\end{align}

## KL divergence


## Mutual Information

The mutual information measures the dependence of two random variables, and defined as follows. 

Let $X$ and $Y$ be two (discrete) random variables, then the mutual information is
\begin{align}
  I(X;Y) = D_{KL}(P_{XY}) || P_X \otimes P_Y)  = \sum_y \sum_x P_{XY}(x,y) \log\Big(\frac{P_XY(x,y)}{P_X(x)P_Y(y)} \Big)
\end{align}

where $D_{KL}$ is KL divergence. Likewise the normalized mutual information (NMI) is 
\begin{align}
  \frac{I(X,Y)}{H(X)H(Y)}
\end{align}
where $H(\cdot)$ is entropy. 


## F1 score

One of the measure to evaluate the performance of classificaiton. F1 score is defined as the harmonic mean of the precision and recall, where
precision = $P(true positive|true positive + false positive)$ and recall = $P(true positive|true positive + false negative)$.
Harmonic mean of $x_1...x_n$ is 
$$
H = \Big\{\frac{\sum_{i=1}^nx_i^{-1}}{n}\Big\}^{-1}
$$

Thus, F1 score is
$$
F1 = \Big[\frac{recall^{-1} + precision^{-1}}{2} \Big]^{-1}
$$











